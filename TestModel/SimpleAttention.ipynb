{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973f64fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8d7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Quant/project/\"\n",
    "targetpath =\"TRAIN.csv\"\n",
    "valpath = \"val.csv\"\n",
    "testpath =\"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20b05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(path+valpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c992b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22_58</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>0.600911</td>\n",
       "      <td>1.081210</td>\n",
       "      <td>-1.635753</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>-0.654596</td>\n",
       "      <td>2.116271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.829991</td>\n",
       "      <td>1.225630</td>\n",
       "      <td>-0.133157</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>-1.329777</td>\n",
       "      <td>0.458489</td>\n",
       "      <td>-1.171452</td>\n",
       "      <td>-1.116468</td>\n",
       "      <td>-1.403561</td>\n",
       "      <td>1.496008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22_59</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.148273</td>\n",
       "      <td>-1.107688</td>\n",
       "      <td>-0.762889</td>\n",
       "      <td>0.759441</td>\n",
       "      <td>-0.661708</td>\n",
       "      <td>0.614619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329355</td>\n",
       "      <td>1.225630</td>\n",
       "      <td>0.335490</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>0.752005</td>\n",
       "      <td>0.366660</td>\n",
       "      <td>-1.171452</td>\n",
       "      <td>0.843250</td>\n",
       "      <td>0.520654</td>\n",
       "      <td>0.824550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22_61</td>\n",
       "      <td>22</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.595294</td>\n",
       "      <td>0.776524</td>\n",
       "      <td>0.546407</td>\n",
       "      <td>0.045971</td>\n",
       "      <td>-0.606577</td>\n",
       "      <td>-0.313791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.076004</td>\n",
       "      <td>-0.815907</td>\n",
       "      <td>-0.349123</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>0.752005</td>\n",
       "      <td>-0.404179</td>\n",
       "      <td>0.084959</td>\n",
       "      <td>-0.250347</td>\n",
       "      <td>-0.819772</td>\n",
       "      <td>-0.118027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22_62</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.983207</td>\n",
       "      <td>-0.227873</td>\n",
       "      <td>0.400930</td>\n",
       "      <td>-1.453166</td>\n",
       "      <td>0.601058</td>\n",
       "      <td>4.339244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840153</td>\n",
       "      <td>-0.815907</td>\n",
       "      <td>-0.667887</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>-1.329777</td>\n",
       "      <td>3.346428</td>\n",
       "      <td>-1.171452</td>\n",
       "      <td>-0.388681</td>\n",
       "      <td>1.211371</td>\n",
       "      <td>4.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22_63</td>\n",
       "      <td>22</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.229776</td>\n",
       "      <td>-0.004463</td>\n",
       "      <td>-0.035502</td>\n",
       "      <td>2.124675</td>\n",
       "      <td>-0.658155</td>\n",
       "      <td>-0.573081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808395</td>\n",
       "      <td>-0.815907</td>\n",
       "      <td>-0.425994</td>\n",
       "      <td>0.338368</td>\n",
       "      <td>0.752005</td>\n",
       "      <td>-0.606159</td>\n",
       "      <td>-1.171452</td>\n",
       "      <td>0.717530</td>\n",
       "      <td>-1.274164</td>\n",
       "      <td>-0.703374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>33_213</td>\n",
       "      <td>33</td>\n",
       "      <td>213</td>\n",
       "      <td>-1.414616</td>\n",
       "      <td>0.833006</td>\n",
       "      <td>-1.078762</td>\n",
       "      <td>-0.972510</td>\n",
       "      <td>2.457652</td>\n",
       "      <td>-0.235570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120991</td>\n",
       "      <td>-0.657001</td>\n",
       "      <td>-0.324576</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>-0.382438</td>\n",
       "      <td>-0.283733</td>\n",
       "      <td>-0.444719</td>\n",
       "      <td>1.520904</td>\n",
       "      <td>-0.176580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>33_214</td>\n",
       "      <td>33</td>\n",
       "      <td>214</td>\n",
       "      <td>-0.006400</td>\n",
       "      <td>-0.584242</td>\n",
       "      <td>0.633364</td>\n",
       "      <td>0.188913</td>\n",
       "      <td>-0.773373</td>\n",
       "      <td>-0.483320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446051</td>\n",
       "      <td>-0.657001</td>\n",
       "      <td>-0.452254</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>-0.401591</td>\n",
       "      <td>-0.283733</td>\n",
       "      <td>-0.329566</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>-0.484327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>33_216</td>\n",
       "      <td>33</td>\n",
       "      <td>216</td>\n",
       "      <td>-0.275792</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>1.204072</td>\n",
       "      <td>0.267470</td>\n",
       "      <td>-0.389980</td>\n",
       "      <td>-0.500376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619648</td>\n",
       "      <td>-0.657001</td>\n",
       "      <td>-1.341064</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>-1.211851</td>\n",
       "      <td>-0.528420</td>\n",
       "      <td>0.992241</td>\n",
       "      <td>-0.913289</td>\n",
       "      <td>-0.411646</td>\n",
       "      <td>-0.506684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>33_217</td>\n",
       "      <td>33</td>\n",
       "      <td>217</td>\n",
       "      <td>-0.934072</td>\n",
       "      <td>0.528163</td>\n",
       "      <td>-1.649470</td>\n",
       "      <td>-1.010666</td>\n",
       "      <td>1.146295</td>\n",
       "      <td>-0.087223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394762</td>\n",
       "      <td>-0.657001</td>\n",
       "      <td>-0.934546</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>-0.255277</td>\n",
       "      <td>0.992241</td>\n",
       "      <td>-0.845721</td>\n",
       "      <td>-0.133167</td>\n",
       "      <td>-0.050718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>33_218</td>\n",
       "      <td>33</td>\n",
       "      <td>218</td>\n",
       "      <td>-0.925161</td>\n",
       "      <td>-0.320688</td>\n",
       "      <td>1.917458</td>\n",
       "      <td>-0.796179</td>\n",
       "      <td>1.781502</td>\n",
       "      <td>-0.398205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086799</td>\n",
       "      <td>-0.657001</td>\n",
       "      <td>0.119822</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>-0.417409</td>\n",
       "      <td>0.992241</td>\n",
       "      <td>-1.102599</td>\n",
       "      <td>1.377287</td>\n",
       "      <td>-0.373196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  row_id  time_id  investment_id    target       f_0  \\\n",
       "0               0   22_58       22             58  0.600911  1.081210   \n",
       "1               1   22_59       22             59 -0.148273 -1.107688   \n",
       "2               2   22_61       22             61 -0.595294  0.776524   \n",
       "3               3   22_62       22             62 -0.983207 -0.227873   \n",
       "4               4   22_63       22             63 -0.229776 -0.004463   \n",
       "...           ...     ...      ...            ...       ...       ...   \n",
       "24995       24995  33_213       33            213 -1.414616  0.833006   \n",
       "24996       24996  33_214       33            214 -0.006400 -0.584242   \n",
       "24997       24997  33_216       33            216 -0.275792  0.087031   \n",
       "24998       24998  33_217       33            217 -0.934072  0.528163   \n",
       "24999       24999  33_218       33            218 -0.925161 -0.320688   \n",
       "\n",
       "            f_1       f_2       f_3       f_4  ...     f_290     f_291  \\\n",
       "0     -1.635753  0.082000 -0.654596  2.116271  ...  1.829991  1.225630   \n",
       "1     -0.762889  0.759441 -0.661708  0.614619  ...  0.329355  1.225630   \n",
       "2      0.546407  0.045971 -0.606577 -0.313791  ... -1.076004 -0.815907   \n",
       "3      0.400930 -1.453166  0.601058  4.339244  ...  0.840153 -0.815907   \n",
       "4     -0.035502  2.124675 -0.658155 -0.573081  ...  0.808395 -0.815907   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "24995 -1.078762 -0.972510  2.457652 -0.235570  ... -0.120991 -0.657001   \n",
       "24996  0.633364  0.188913 -0.773373 -0.483320  ...  0.446051 -0.657001   \n",
       "24997  1.204072  0.267470 -0.389980 -0.500376  ... -0.619648 -0.657001   \n",
       "24998 -1.649470 -1.010666  1.146295 -0.087223  ...  0.394762 -0.657001   \n",
       "24999  1.917458 -0.796179  1.781502 -0.398205  ... -0.086799 -0.657001   \n",
       "\n",
       "          f_292     f_293     f_294     f_295     f_296     f_297     f_298  \\\n",
       "0     -0.133157  0.338368 -1.329777  0.458489 -1.171452 -1.116468 -1.403561   \n",
       "1      0.335490  0.338368  0.752005  0.366660 -1.171452  0.843250  0.520654   \n",
       "2     -0.349123  0.338368  0.752005 -0.404179  0.084959 -0.250347 -0.819772   \n",
       "3     -0.667887  0.338368 -1.329777  3.346428 -1.171452 -0.388681  1.211371   \n",
       "4     -0.425994  0.338368  0.752005 -0.606159 -1.171452  0.717530 -1.274164   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995 -0.324576  0.173576  0.825183 -0.382438 -0.283733 -0.444719  1.520904   \n",
       "24996 -0.452254  0.173576  0.825183 -0.401591 -0.283733 -0.329566  0.846726   \n",
       "24997 -1.341064  0.173576 -1.211851 -0.528420  0.992241 -0.913289 -0.411646   \n",
       "24998 -0.934546  0.173576  0.825183 -0.255277  0.992241 -0.845721 -0.133167   \n",
       "24999  0.119822  0.173576  0.825183 -0.417409  0.992241 -1.102599  1.377287   \n",
       "\n",
       "          f_299  \n",
       "0      1.496008  \n",
       "1      0.824550  \n",
       "2     -0.118027  \n",
       "3      4.564400  \n",
       "4     -0.703374  \n",
       "...         ...  \n",
       "24995 -0.176580  \n",
       "24996 -0.484327  \n",
       "24997 -0.506684  \n",
       "24998 -0.050718  \n",
       "24999 -0.373196  \n",
       "\n",
       "[25000 rows x 305 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee31a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#两方面去考虑attention,首先,可以忽视事件数据,将所有Id一样的人聚集在一起,将他们视作一个sequence,将他们的target作为另一个,观察两个sequence的关系\n",
    "#其次,可以以同一个时域做Attention,将这个时域中的数据作为一个切面sequence,然后跟他们的结果做相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebc158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDataFromKaggle():\n",
    "    print(\"successful get date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3603bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMaxFeature(x):\n",
    "    id_size = x[\"investment_id\"].nunique()\n",
    "    time_id_size = x[\"time_id\"].nunique()\n",
    "    return id_size,time_id_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4562374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ubiquant(Dataset):\n",
    "    def __init__(self,datapath,context = 100,train_data = True,get_time_data = True):\n",
    "        super(Ubiquant,self).__init__()\n",
    "        self.get_time = get_time_data\n",
    "        if(train_data):\n",
    "            self.data = pd.read_csv(datapath)\n",
    "            self.id_size,self.time_size = GetMaxFeature(self.data)\n",
    "            if(get_time_data):#get an x,y base on time frame\n",
    "                self.y = self.data.loc[:,\"target\"]\n",
    "                self.x = self.data.drop(columns=[\"Unnamed: 0\",\"row_id\",\"target\"])\n",
    "                self.x.loc[:,\"time_id\"] -=self.x.loc[0,\"time_id\"]\n",
    "                #self.id = self.x[[\"time_id\"]]\n",
    "                self.id = self.x[[\"investment_id\"]]\n",
    "                self.x = self.x.drop(columns=[\"investment_id\"])\n",
    "                #self.x = self.x.drop(columns=[\"time_id\"])\n",
    "            else:#get (x,y) base on investment_id\n",
    "                self.data = self.data.sort_values(by=[\"investment_id\"])\n",
    "                self.y = self.data.loc[:,\"target\"]\n",
    "                self.x = self.data.drop(columns=[\"Unnamed: 0\",\"row_id\",\"time_id\",\"target\"])\n",
    "                self.id = self.x[[\"investment_id\"]]\n",
    "                self.x = self.x.drop(columns=[\"investment_id\"])\n",
    "        \n",
    "        #pad context before the data\n",
    "        self.context = context\n",
    "        self.pad_id =np.pad(self.id.to_numpy(),((context-1,0),(0,0)),constant_values = 0)\n",
    "        self.pad_x =np.pad(self.x.to_numpy(),((context-1,0),(0,0)),constant_values = 0)\n",
    "        self.y =self.y.to_numpy()\n",
    "        \n",
    "        \n",
    "        self.pad_id =torch.LongTensor(self.pad_id)\n",
    "        self.pad_x = torch.FloatTensor(self.pad_x)\n",
    "        self.y = torch.FloatTensor(self.y)\n",
    "        \n",
    "        print(f\"succesfully load data with shape x : {self.x.shape} | shape y :{self.y.shape} | get time data is: {get_time_data}\")\n",
    "        \n",
    "                \n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        context = self.context\n",
    "        return self.pad_id[index:index+context],self.pad_x[index:index+context],self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def GetSize(self):\n",
    "        if(get_time_data):\n",
    "            return self.time_size\n",
    "        else:\n",
    "            return self.id_size\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfea802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(get_time_data = True):\n",
    "    trainSet =Ubiquant(path+targetpath,context = config[\"context\"], get_time_data = get_time_data)\n",
    "    valSet =Ubiquant(path+valpath, context = config[\"context\"], get_time_data = get_time_data)\n",
    "    testSet =Ubiquant(path+testpath, context = config[\"context\"], get_time_data = get_time_data)\n",
    "    trainLoader = DataLoader(trainSet,batch_size = config[\"batch_size\"],shuffle =True,drop_last=True)#,num_workers=2)\n",
    "    valLoader = DataLoader(valSet,batch_size = config[\"batch_size\"],shuffle =True,drop_last=True)#,num_workers=2)\n",
    "    testLoader = DataLoader(testSet,batch_size = config[\"batch_size\"],shuffle =False,drop_last=False)\n",
    "    return trainLoader,valLoader,testLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0d5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self,seq_len = 32, input_feature =311):\n",
    "        super(SimpleAttention,self).__init__() \n",
    "        \n",
    "        self.id_embedding = nn.Embedding(10000,11)\n",
    "        self.att = nn.MultiheadAttention(input_feature,8,batch_first=True)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.MLP =nn.Sequential(\n",
    "            nn.Linear(input_feature*seq_len,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(8,1)\n",
    "        )\n",
    "            \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,_id,f_features):\n",
    "        invest_embedding = self.id_embedding(_id).squeeze(dim=2)\n",
    "        #print(invest_embedding.shape)\n",
    "        #print(f_features.shape)\n",
    "        _input =torch.cat((invest_embedding,f_features),axis =-1)\n",
    "        #print(_input.shape)\n",
    "        #_input = _input.unsqueeze(dim=1)\n",
    "        #print(_input.shape)\n",
    "        output,_ = self.att(_input,_input,_input)\n",
    "        #print(output.shape)\n",
    "        output = self.flat(output)\n",
    "        #print(output.shape)\n",
    "        output = self.MLP(output)\n",
    "        return output\n",
    "    \n",
    "    def cal_Loss(self,y_hat,y):\n",
    "        return self.criterion(y_hat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0838ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self,seq_len = 32,input_feature = 311):\n",
    "        super(SimpleMLP,self).__init__()\n",
    "        \n",
    "        self.id_embedding = nn.Embedding(10000,11)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.MLP =nn.Sequential(\n",
    "            nn.Linear(input_feature*seq_len,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(8,1)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,_id,f_features):\n",
    "        invest_embedding = self.id_embedding(_id).squeeze(dim=2)\n",
    "        #print(invest_embedding.shape)\n",
    "        #print(f_features.shape)\n",
    "        _input =torch.cat((invest_embedding,f_features),axis =-1)\n",
    "        #print(_input.shape)\n",
    "        #_input = _input.unsqueeze(dim=1)\n",
    "        #print(_input.shape)\n",
    "        _input = self.flat(_input)\n",
    "        output = self.MLP(_input)\n",
    "        return output\n",
    "\n",
    "    def cal_Loss(self,y_hat,y):\n",
    "        return self.criterion(y_hat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdf7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(y,target):\n",
    "    y,target = y.reshape(-1),target.reshape(-1)\n",
    "    ymean,targetmean = torch.mean(y),torch.mean(target)\n",
    "    \n",
    "    vy = y-ymean\n",
    "    vt = target-targetmean\n",
    "    \n",
    "    corr = torch.sum(vy*vt)/(torch.sqrt(torch.sum(vy**2))* torch.sqrt(torch.sum(vt**2)))\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "111db94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainLoader,valLoader, optimizer, scheduler, config):\n",
    "    best_loss =1000\n",
    "    epochs =config[\"epoch\"]\n",
    "    for epoch in range(epochs):\n",
    "        batch_bar = tqdm(total = len(trainLoader),dynamic_ncols = True,leave =False,position = 0,desc = \"train\")\n",
    "        model.train()\n",
    "        train_total_loss = 0\n",
    "        for i,(x1,x2,y) in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            x1,x2,y = x1.cuda(),x2.cuda(),y.cuda()\n",
    "            y_hat = model(x1,x2)\n",
    "            y_hat = y_hat.reshape(-1,1)\n",
    "            y =y.reshape(-1,1)\n",
    "            loss = model.cal_Loss(y_hat,y)\n",
    "            train_total_loss+=float(loss.cpu())\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(float(train_total_loss / (i + 1))),\n",
    "                lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            batch_bar.update()\n",
    "        batch_bar.close()\n",
    "        \n",
    "        val_total_loss = 0\n",
    "        val_total_corr = 0\n",
    "        batch_bar = tqdm(total = len(valLoader),dynamic_ncols = True,leave =False,position = 0,desc = \"val\")\n",
    "        model.eval()\n",
    "        for i,(x1,x2,y) in enumerate(valLoader):\n",
    "            with torch.no_grad():\n",
    "                x1,x2,y = x1.cuda(),x2.cuda(),y.cuda()\n",
    "                y_hat = model(x1,x2)\n",
    "                y_hat = y_hat.reshape(-1,1)\n",
    "                y =y.reshape(-1,1)\n",
    "                loss = model.cal_Loss(y_hat,y)\n",
    "                \n",
    "\n",
    "                corr = get_corr(y_hat,y)\n",
    "                val_total_corr+=corr\n",
    "               \n",
    "                val_total_loss+=loss\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(float(val_total_loss / (i + 1))),\n",
    "                \n",
    "                corr=\"{:.04f}\".format(float(val_total_corr / (i + 1))),\n",
    "             )\n",
    "            batch_bar.update()\n",
    "        batch_bar.close()\n",
    "        val_loss = float(val_total_loss/len(valLoader))\n",
    "        if(val_loss<best_loss):\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(),config[\"store_path\"])\n",
    "            print(\"successfully save model\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: train loss {float(train_total_loss / len(trainLoader)):0.04f}, Learning Rate {optimizer.param_groups[0]['lr']:0.04f}, val loss{float(val_total_loss/len(valLoader)):0.04f}, corr {float(val_total_corr / (i + 1)):0.04f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ca5deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,testLoader,config):\n",
    "    model.load_state_dict(torch.load(config[\"store_path\"]))\n",
    "    model.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_corr = 0\n",
    "    batch_bar = tqdm(total = len(testLoader),dynamic_ncols = True,leave =False,position = 0,desc = \"Test\")\n",
    "    for i,(x1,x2,y) in enumerate(testLoader):\n",
    "        with torch.no_grad():\n",
    "            x1,x2,y = x1.cuda(),x2.cuda(),y.cuda()\n",
    "            y_hat = model(x1,x2)\n",
    "            y_hat = y_hat.reshape(-1,1)\n",
    "            y =y.reshape(-1,1)\n",
    "            loss = model.cal_Loss(y_hat,y)\n",
    "                \n",
    "\n",
    "            corr = get_corr(y_hat,y)\n",
    "            test_total_corr+=corr\n",
    "            test_total_loss+=loss\n",
    "        batch_bar.set_postfix(\n",
    "                test_loss=\"{:.04f}\".format(float(test_total_loss / (i + 1))),\n",
    "                \n",
    "                test_corr=\"{:.04f}\".format(float(test_total_corr / (i + 1))),\n",
    "             )\n",
    "        batch_bar.update()\n",
    "    batch_bar.close()\n",
    "    print(f\"test loss{float(test_total_loss/len(testLoader)):0.04f},test corr {float(test_total_corr / len(testLoader)):0.04f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "633f0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main():\n",
    "    #set all parameter\n",
    "    trainLoader,valLoader,testLoader = LoadData(get_time_data = True)\n",
    "    model = SimpleAttention(32,312).cuda()\n",
    "    model.train()\n",
    "    baseline_model = SimpleMLP(32,312).cuda()\n",
    "    baseline_model.train()\n",
    "    optimizer = getattr(torch.optim,config[\"optimz\"])(model.parameters(),lr =config[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(trainLoader) * config[\"epoch\"]))\n",
    "    \n",
    "    \n",
    "    base_optimizer = getattr(torch.optim,config[\"optimz\"])(model.parameters(),lr =config[\"learning_rate\"])\n",
    "    base_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(trainLoader) * config[\"epoch\"]))\n",
    "    #params\n",
    "    num_para =0\n",
    "    for p in model.parameters():\n",
    "        num_para+=p.numel()\n",
    "    print(f'Number of params : {num_para}')\n",
    "    \n",
    "    train(model,trainLoader,valLoader,optimizer,scheduler,config)\n",
    "    print(\"///////////Start Train Base Line//////////\")\n",
    "    train(baseline_model,trainLoader,valLoader,base_optimizer,base_scheduler,base_config)\n",
    "    \n",
    "    print(\"//////////Start test///////////\")\n",
    "    print(\"----BaseLine-----\")\n",
    "    test(baseline_model,testLoader,base_config)\n",
    "    print(\"----Attention-----\")\n",
    "    test(model,testLoader,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fd12bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"epoch\" : 50,\"batch_size\":12800,\"learning_rate\":0.1,\"optimz\":\"Adam\",\"store_path\":\"C:/Quant/project/Att.pth\",\"context\":32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c1657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config={\"epoch\" : 50,\"batch_size\":12800,\"learning_rate\":0.1,\"optimz\":\"Adam\",\"store_path\":\"C:/Quant/project/MLP.pth\",\"context\":32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29b82d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully load data with shape x : (50000, 301) | shape y :torch.Size([50000]) | get time data is: True\n",
      "succesfully load data with shape x : (25000, 301) | shape y :torch.Size([25000]) | get time data is: True\n",
      "succesfully load data with shape x : (25000, 301) | shape y :torch.Size([25000]) | get time data is: True\n",
      "Number of params : 1480561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: train loss 0.9527, Learning Rate 0.0999, val loss76754.8203, corr -0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 2/50: train loss 0.8965, Learning Rate 0.0996, val loss3.7568, corr -0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 3/50: train loss 0.9008, Learning Rate 0.0991, val loss2.0762, corr -0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: train loss 0.8988, Learning Rate 0.0984, val loss2.8428, corr -0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 5/50: train loss 0.8996, Learning Rate 0.0976, val loss0.8839, corr 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 6/50: train loss 0.8935, Learning Rate 0.0965, val loss0.8685, corr 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 7/50: train loss 0.8897, Learning Rate 0.0952, val loss0.8678, corr 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: train loss 0.8911, Learning Rate 0.0938, val loss0.8887, corr 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: train loss 0.8995, Learning Rate 0.0922, val loss0.8787, corr -0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: train loss 0.8953, Learning Rate 0.0905, val loss0.8959, corr 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 11/50: train loss 0.8827, Learning Rate 0.0885, val loss0.8543, corr 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 12/50: train loss 0.8849, Learning Rate 0.0864, val loss0.8485, corr 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: train loss 0.8913, Learning Rate 0.0842, val loss0.8760, corr 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: train loss 0.8918, Learning Rate 0.0819, val loss0.8749, corr 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: train loss 0.8846, Learning Rate 0.0794, val loss0.8689, corr 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: train loss 0.8915, Learning Rate 0.0768, val loss0.8799, corr 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: train loss 0.8841, Learning Rate 0.0741, val loss0.8489, corr -0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: train loss 0.8892, Learning Rate 0.0713, val loss0.8878, corr 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: train loss 0.8807, Learning Rate 0.0684, val loss0.8725, corr -0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: train loss 0.8966, Learning Rate 0.0655, val loss0.8756, corr 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: train loss 0.8831, Learning Rate 0.0624, val loss0.8651, corr 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: train loss 0.8856, Learning Rate 0.0594, val loss0.8768, corr 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: train loss 0.9025, Learning Rate 0.0563, val loss0.8676, corr 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: train loss 0.8882, Learning Rate 0.0531, val loss0.8960, corr 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 25/50: train loss 0.8868, Learning Rate 0.0500, val loss0.8347, corr 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: train loss 0.8939, Learning Rate 0.0469, val loss0.8555, corr 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: train loss 0.8838, Learning Rate 0.0437, val loss0.8719, corr 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: train loss 0.8900, Learning Rate 0.0406, val loss0.8409, corr 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: train loss 0.8967, Learning Rate 0.0376, val loss0.8691, corr 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: train loss 0.8811, Learning Rate 0.0345, val loss0.8730, corr 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: train loss 0.8974, Learning Rate 0.0316, val loss0.8652, corr 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: train loss 0.8990, Learning Rate 0.0287, val loss0.8608, corr 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: train loss 0.8846, Learning Rate 0.0259, val loss0.8743, corr 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: train loss 0.8919, Learning Rate 0.0232, val loss0.8793, corr 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: train loss 0.8872, Learning Rate 0.0206, val loss0.8598, corr 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: train loss 0.8956, Learning Rate 0.0181, val loss0.8629, corr 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: train loss 0.8901, Learning Rate 0.0158, val loss0.8596, corr 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: train loss 0.8898, Learning Rate 0.0136, val loss0.8535, corr 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: train loss 0.9000, Learning Rate 0.0115, val loss0.8587, corr 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: train loss 0.8917, Learning Rate 0.0095, val loss0.8463, corr 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: train loss 0.8828, Learning Rate 0.0078, val loss0.8556, corr 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: train loss 0.8869, Learning Rate 0.0062, val loss0.8657, corr 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: train loss 0.8945, Learning Rate 0.0048, val loss0.8770, corr 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: train loss 0.8790, Learning Rate 0.0035, val loss0.8785, corr 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: train loss 0.8912, Learning Rate 0.0024, val loss0.8679, corr 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: train loss 0.8861, Learning Rate 0.0016, val loss0.8566, corr 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: train loss 0.8916, Learning Rate 0.0009, val loss0.8593, corr 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: train loss 0.8844, Learning Rate 0.0004, val loss0.8732, corr 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: train loss 0.8880, Learning Rate 0.0001, val loss0.8608, corr 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: train loss 0.8900, Learning Rate 0.0000, val loss0.8612, corr 0.0113\n",
      "///////////Start Train Base Line//////////\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 1/50: train loss 1.1473, Learning Rate 0.1000, val loss0.9951, corr 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 2/50: train loss 1.1434, Learning Rate 0.1000, val loss0.9752, corr 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: train loss 1.1538, Learning Rate 0.1000, val loss0.9795, corr 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: train loss 1.1696, Learning Rate 0.1000, val loss0.9758, corr 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 5/50: train loss 1.1446, Learning Rate 0.1000, val loss0.9649, corr 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: train loss 1.1439, Learning Rate 0.1000, val loss0.9829, corr 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: train loss 1.1541, Learning Rate 0.1000, val loss0.9849, corr 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: train loss 1.1579, Learning Rate 0.1000, val loss0.9650, corr -0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: train loss 1.1481, Learning Rate 0.1000, val loss0.9698, corr 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: train loss 1.1362, Learning Rate 0.1000, val loss1.0042, corr -0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: train loss 1.1535, Learning Rate 0.1000, val loss0.9765, corr -0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: train loss 1.1430, Learning Rate 0.1000, val loss0.9853, corr 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: train loss 1.1595, Learning Rate 0.1000, val loss0.9677, corr 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 14/50: train loss 1.1505, Learning Rate 0.1000, val loss0.9632, corr 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: train loss 1.1438, Learning Rate 0.1000, val loss0.9818, corr -0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: train loss 1.1444, Learning Rate 0.1000, val loss0.9899, corr 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: train loss 1.1475, Learning Rate 0.1000, val loss0.9786, corr -0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: train loss 1.1546, Learning Rate 0.1000, val loss0.9967, corr 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: train loss 1.1592, Learning Rate 0.1000, val loss1.0099, corr 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: train loss 1.1503, Learning Rate 0.1000, val loss0.9813, corr -0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: train loss 1.1538, Learning Rate 0.1000, val loss0.9800, corr 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: train loss 1.1527, Learning Rate 0.1000, val loss0.9813, corr -0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: train loss 1.1401, Learning Rate 0.1000, val loss0.9839, corr -0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: train loss 1.1511, Learning Rate 0.1000, val loss0.9934, corr -0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: train loss 1.1467, Learning Rate 0.1000, val loss0.9788, corr -0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully save model\n",
      "Epoch 26/50: train loss 1.1376, Learning Rate 0.1000, val loss0.9460, corr 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: train loss 1.1448, Learning Rate 0.1000, val loss0.9828, corr -0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: train loss 1.1463, Learning Rate 0.1000, val loss0.9672, corr -0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: train loss 1.1478, Learning Rate 0.1000, val loss0.9497, corr 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: train loss 1.1540, Learning Rate 0.1000, val loss0.9535, corr -0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: train loss 1.1464, Learning Rate 0.1000, val loss0.9674, corr 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: train loss 1.1632, Learning Rate 0.1000, val loss0.9736, corr -0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: train loss 1.1463, Learning Rate 0.1000, val loss0.9933, corr -0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: train loss 1.1541, Learning Rate 0.1000, val loss0.9544, corr 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: train loss 1.1467, Learning Rate 0.1000, val loss0.9893, corr 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: train loss 1.1616, Learning Rate 0.1000, val loss0.9564, corr -0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: train loss 1.1485, Learning Rate 0.1000, val loss0.9611, corr 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: train loss 1.1562, Learning Rate 0.1000, val loss0.9993, corr -0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: train loss 1.1645, Learning Rate 0.1000, val loss0.9961, corr 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: train loss 1.1565, Learning Rate 0.1000, val loss0.9616, corr 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: train loss 1.1407, Learning Rate 0.1000, val loss0.9757, corr 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: train loss 1.1477, Learning Rate 0.1000, val loss0.9559, corr 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: train loss 1.1468, Learning Rate 0.1000, val loss0.9708, corr -0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: train loss 1.1502, Learning Rate 0.1000, val loss0.9764, corr 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: train loss 1.1412, Learning Rate 0.1000, val loss0.9885, corr 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: train loss 1.1407, Learning Rate 0.1000, val loss0.9872, corr 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: train loss 1.1582, Learning Rate 0.1000, val loss0.9974, corr 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: train loss 1.1426, Learning Rate 0.1000, val loss0.9604, corr 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: train loss 1.1449, Learning Rate 0.1000, val loss0.9840, corr 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: train loss 1.1464, Learning Rate 0.1000, val loss0.9673, corr 0.0019\n",
      "//////////Start test///////////\n",
      "----BaseLine-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss0.9561,test corr 0.0116\n",
      "----Attention-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss0.8567,test corr 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b1992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e32f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5c3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
